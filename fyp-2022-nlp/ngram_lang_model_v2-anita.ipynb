{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline, flatten, everygrams, pad_both_ends\n",
    "from collections import Counter\n",
    "from nltk.lm import Laplace, KneserNeyInterpolated, WittenBellInterpolated, StupidBackoff\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "import pandas as pd\n",
    "from nltk import FreqDist, KneserNeyProbDist\n",
    "from nltk.util import bigrams, trigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.lm import NgramCounter\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.api import LanguageModel, Smoothing\n",
    "from nltk.lm.smoothing import AbsoluteDiscounting, KneserNey, WittenBell\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk.lm as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'data/hate/train_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_PATH, 'r', encoding = 'utf-8') as f:\n",
    "    dataset = f.readlines()\n",
    "    \n",
    "split = round(len(dataset)*0.8)\n",
    "train_data = dataset[:split]\n",
    "test_data = dataset[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized_data = [list(map(str.lower, nltk.tokenize.word_tokenize(sent))) \n",
    "                for sent in train_data]\n",
    "\n",
    "test_tokenized_data = [list(map(str.lower, nltk.tokenize.word_tokenize(sent))) \n",
    "                for sent in test_data]\n",
    "\n",
    "test_tokenized_data = [sent for sent in test_tokenized_data if sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "train, vocab = padded_everygram_pipeline(n, train_tokenized_data)\n",
    "# test, vocab = padded_everygram_pipeline(n, test_tokenized_data)\n",
    "test = list(ngrams(list(pad_both_ends(test_tokenized_data, n=n)), n))\n",
    "\n",
    "kn = KneserNeyInterpolated(n) \n",
    "kn.fit(train, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 6, perplexity: inf\n",
      "index: 7, perplexity: inf\n",
      "index: 8, perplexity: inf\n",
      "index: 16, perplexity: inf\n",
      "index: 17, perplexity: inf\n",
      "index: 18, perplexity: inf\n",
      "index: 25, perplexity: inf\n",
      "index: 26, perplexity: inf\n",
      "index: 27, perplexity: inf\n",
      "index: 28, perplexity: inf\n",
      "index: 29, perplexity: inf\n",
      "index: 30, perplexity: inf\n",
      "index: 44, perplexity: inf\n",
      "index: 45, perplexity: inf\n",
      "index: 46, perplexity: inf\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(test[:50]):\n",
    "    try:\n",
    "        val = kn.perplexity(t)\n",
    "    except ZeroDivisionError:\n",
    "        val = \"tu by≈Ço 0\"\n",
    "    except TypeError:\n",
    "        val = \"x\"\n",
    "    print(f\"index: {i}, perplexity: {val}\") if (val == np.inf or val == \"x\") else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'read',\n",
       " 'world',\n",
       " \"relief's\",\n",
       " 'response',\n",
       " 'to',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'scotus',\n",
       " 'opinion',\n",
       " 'of',\n",
       " 'refugee',\n",
       " 'resettlement.https',\n",
       " ':/',\n",
       " '/',\n",
       " 't.co/hiwv8hezm1',\n",
       " '</s>',\n",
       " '</s>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(pad_both_ends(test_tokenized_data[6], n=n))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ('<s>', '<s>')\n",
      "0.0008325276637006617 \n",
      "\n",
      "world ('<s>', 'read')\n",
      "2.5845596623317364e-06 \n",
      "\n",
      "relief's ('read', 'world')\n",
      "0.01652240871350772 \n",
      "\n",
      "response ('world', \"relief's\")\n",
      "1.3903148528405205e-06 \n",
      "\n",
      "to (\"relief's\", 'response')\n",
      "0.4223072198591962 \n",
      "\n",
      "the ('response', 'to')\n",
      "0.003605245049780589 \n",
      "\n",
      "latest ('to', 'the')\n",
      "0.005289773508389742 \n",
      "\n",
      "scotus ('the', 'latest')\n",
      "3.948823250671301e-07 \n",
      "\n",
      "opinion ('latest', 'scotus')\n",
      "0.12857998435513837 \n",
      "\n",
      "of ('scotus', 'opinion')\n",
      "8.609257357973991e-05 \n",
      "\n",
      "refugee ('opinion', 'of')\n",
      "0.0021335010786854816 \n",
      "\n",
      "resettlement.https ('of', 'refugee')\n",
      "0.0 \n",
      "\n",
      ":/ ('refugee', 'resettlement.https')\n",
      "0.0006630732375085558 \n",
      "\n",
      "/ ('resettlement.https', ':/')\n",
      "0.9661373120487513 \n",
      "\n",
      "t.co/hiwv8hezm1 (':/', '/')\n",
      "0.0 \n",
      "\n",
      "</s> ('/', 't.co/hiwv8hezm1')\n",
      "0.02277977412731006 \n",
      "\n",
      "</s> ('t.co/hiwv8hezm1', '</s>')\n",
      "0.999954099566657 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in trigrams(x):\n",
    "    print(t[2], t[:2])\n",
    "    print(kn.score(t[2], t[:2]), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.score(\"yousuck\", ['#']) #1744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.score(\"yousuck\", ['.', '#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.score(\"yousuck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Counter(train_list_hate).most_common()[::-1]\n",
    "print(f\"HATE\\n\\nvocabulary_size: {len(x)}\\ncorpus size: {len(train_list_hate)}\\ntoken/types ratio: {len(train_list_hate)/len(x)}\")\n",
    "y = Counter(train_list_sentiment).most_common()[::-1]\n",
    "print(f\"\\nSENTIMENT\\n\\nvocabulary_size: {len(y)}\\ncorpus size: {len(train_list_sentiment)}\\ntoken/types ratio: {len(train_list_sentiment)/len(y)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
